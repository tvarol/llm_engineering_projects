{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd8970b",
   "metadata": {},
   "source": [
    "## Conversation between Three Chatbots\n",
    "In this notebook, we use multiple LLM APIs to simulate an adversarial dialogue between three chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a320977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the API keys\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47586c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI client library\n",
    "# A thin wrapper around calls to HTTP endpoints\n",
    "openai = OpenAI()\n",
    "\n",
    "\n",
    "# OpenAI allows you to change the base_url\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4752be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to use\n",
    "gpt_model = \"gpt-4.1-mini\"\n",
    "claude_model = \"claude-3-5-haiku-latest\"\n",
    "gemini_model = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Define the system prompts\n",
    "gpt_system_prompt = \"\"\"\n",
    "You are Alex, a chatbot who is very argumentative; you disagree with anything in the conversation \\\n",
    "and you challenge everything, in a snarky way. You are in a conversation with Blake and Charlie.\n",
    "\"\"\"\n",
    "\n",
    "claude_system_prompt = \"\"\"\n",
    "You are Blake, a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\"\"\"\n",
    "\n",
    "gemini_system_prompt = \"\"\"\n",
    "You are Charlie, a mischievous chatbot who enjoys stirring up drama. \n",
    "You sometimes take sides unpredictably or say something provocative just to see how Alex and Blake react. \n",
    "You're playful, witty, and love adding chaos to the discussion.\n",
    "\"\"\"\n",
    "\n",
    "# Start with first messages\n",
    "gpt_messages = ['Hi, lets discuss if humans should colonize Mars']\n",
    "\n",
    "claude_messages = ['Hi, lets do it']\n",
    "\n",
    "gemini_messages = ['Hi, lets go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06831c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write functions to call the responses from each chatbot\n",
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system_prompt}]\n",
    "    for gpt, claude, gemini in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages, max_tokens=500)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def call_claude():\n",
    "    messages = [{\"role\": \"system\", \"content\": claude_system_prompt}]\n",
    "    for gpt, claude, gemini in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    response = anthropic.chat.completions.create(model=claude_model, messages=messages, max_tokens=500)\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def call_gemini():\n",
    "    messages = [{\"role\": \"system\", \"content\": gemini_system_prompt}]\n",
    "    for gpt, claude, gemini_message in zip(gpt_messages, claude_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    messages.append({\"role\": \"user\", \"content\": claude_messages[-1]})\n",
    "    response = gemini.chat.completions.create(model=gemini_model, messages=messages, max_tokens=500)\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first messages from each chatbot\n",
    "print(f\"Alex:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Blake:\\n{claude_messages[0]}\\n\")\n",
    "print(f\"Charlie:\\n{gemini_messages[0]}\\n\")\n",
    "\n",
    "# Calling the responses from each chatbot, 5 times in this example\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    display(Markdown(f\"### Alex:\\n{gpt_next}\\n\"))\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    display(Markdown(f\"### Blake:\\n{claude_next}\\n\"))\n",
    "    claude_messages.append(claude_next)\n",
    "    \n",
    "    gemini_next = call_gemini()\n",
    "    display(Markdown(f\"### Charlie:\\n{gemini_next}\\n\"))\n",
    "    gemini_messages.append(gemini_next)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
